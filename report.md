Testing hops=0... BLEU=1.0000
Testing hops=1... BLEU=0.5066
Testing hops=2... BLEU=0.4202
Testing hops=3... BLEU=0.3511
Testing hops=4... BLEU=0.2936
Testing hops=5... BLEU=0.3720
Testing hops=6... BLEU=0.3342
Testing hops=7... BLEU=0.3446
Testing hops=8... BLEU=0.2579
Testing hops=9... BLEU=0.2557
Testing hops=10... BLEU=0.1874
Testing hops=11... BLEU=0.2554
Testing hops=12... BLEU=0.2607
Testing hops=13... BLEU=0.2572
Testing hops=14... BLEU=0.2415
Testing hops=15... BLEU=0.1809
Testing hops=16... BLEU=0.2511
Testing hops=17... BLEU=0.2003
Testing hops=18... BLEU=0.1922
Testing hops=19... BLEU=0.1973
Testing hops=20... BLEU=0.2655

Graph saved to: bleu_scores.png

Summary Statistics:
  Initial BLEU (hops=0): 1.0000
  Final BLEU (hops=20): 0.2655
  Degradation: 73.5%
  Average BLEU: 0.3155
  Min BLEU: 0.1809 (at hops=15)
  Max BLEU: 1.0000 (at hops=0)

Example Degraded Texts:

Hops=0, BLEU=1.0000:
  The temporal sequence of reasoning in Large Language Models is the defining variable of their cognitive architecture. The evidence conclusively demons...

Hops=5, BLEU=0.3720:
  In large language models, the order of inference is a variable that defines the cognitive architecture. Evidence certainly shows that inference coming...

Hops=10, BLEU=0.1874:
  In large language models, inference order is a variable that defines the cognitive architecture. To respect the causal and sequential nature of transf...

Hops=20, BLEU=0.2655:
  In large language models, chain of thought is a dynamic function, it describes the structure of the mind. Considering the causal and sequential nature...

Done!